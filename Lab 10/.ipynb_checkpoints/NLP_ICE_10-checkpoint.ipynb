{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBgH0Dc08SeX"
   },
   "source": [
    "#ICE-10: Spelling Correction in Natural Language Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKEF5g3P-r9i"
   },
   "source": [
    "Please follow the tutorials below and complete the tasks that are available on the webpages provided. The tutorials will have code and might not have dataset file. You can create dataset files as per the tutorial requirements. The aim of the ICE is to make the tutorials in executed format. You can also use the github repositories of the authors if they are avilable. It is recommended to run the tutorials and then test it with your own datasets (Custom made). You can use any source on the internet to complete the tasks. For task 4 your have to provide mini-examples to differentiate between non-word and real world spelling corrections. After the code for task 4 please provide a brief explanation for what is the difference and what is your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAYfpbp-9lMV"
   },
   "source": [
    "# Task 1: (20%)\n",
    "### Use the follwing tutorial to implement spelling checking using Textblob\n",
    "\n",
    "https://stackabuse.com/spelling-correction-in-python-with-textblob/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7_YYKrXd-PK0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aoccdrnig to a rscheearch at Cmabrigde Uinervtisy, it doesn€™t matter in what order the letters in a word are, the only iprmoetnt thing is that the first and last later be at the right place. The set can be a total mess and you can still red it outfit problem. His is bcuseae the human mind does not red even letter by itself, but the word as a whole.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "with open(\n",
    "    \"Typoglycemia.txt\", \"r\"\n",
    ") as f:  # Opening the test file with the intention to read\n",
    "    text = f.read()  # Reading the file\n",
    "    textBlb = TextBlob(text)  # Making our first textblob\n",
    "    textCorrected = textBlb.correct()  # Correcting the text\n",
    "    print(textCorrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MXH3VV28eOj"
   },
   "source": [
    "# Task 2: (20%)\n",
    "### Train your model on custom dataset\n",
    "### Instructions are provided in the above *tutorial*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Z1Z8tLdu-QMB"
   },
   "outputs": [],
   "source": [
    "from textblob.en import Spelling\n",
    "import re\n",
    "\n",
    "textToLower = \"\"\n",
    "\n",
    "with open(\"bible.txt\", \"r\") as f1:  # Open our source file\n",
    "    text = f1.read()  # Read the file\n",
    "    textToLower = text.lower()  # Lower all the capital letters\n",
    "\n",
    "words = re.findall(\n",
    "    \"[a-z]+\", textToLower\n",
    ")  # Find all the words and place them into a list\n",
    "oneString = \" \".join(words)  # Join them into one string\n",
    "\n",
    "pathToFile = \"train.txt\"  # The path we want to store our stats file at\n",
    "spelling = Spelling(path=pathToFile)  # Connect the path to the Spelling object\n",
    "spelling.train(oneString, pathToFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I3Vjj9Mt-QP0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 490/490 [01:18<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  An you name any of the difference eyes of martial art There's far more to them than must grate or king for In face numerous arranged and systemized methods of coat are practiced in the would today. While some staves are very traditional and steeped in history, other are more modern. Although thereof a significant mount of overlay between the styles, their approach to fighting is unique. Familiarize yourself with popular martial art staves with this revile that break down striking, grappling, throwing, weapons-based staves and more Striking or Stand-Up Martial Art Styles Striking or stand-up martial art staves teach practitioners how to deed themselves while on their feet by sing flocks kicks, punches, knees, and elbows. The degree to which they teach each of these aspects depends on the specific stolen sub-style or instructor. Also many of these stand-up staves teach other components of fighting. Striking staves include: Going Capoeira Grate Kickboxing Ram Maga Dung Of May That The Upon To Hang Too To Grappling or Ground-Fighting Styles The grappling staves in martial art four on teaching practitioners how to take opponents to the ground where they neither achieve a dominant position or utilize a submission hold to end the fight Grappling staves include: Brazilian Jiu-Jitsu Watch Wrestling Jujutsu Out Give Russian Lamb Sum Wrestling Throwing or Takedown Styles Combat always stars from a standing position. The only sure way to get a fight to the ground is through the us of takedowns and thrown and thatâ€™s where these thrown staves come into play Not that all of the grappling staves lifted above also teach takedowns, and most of these thrown staves teach grappling. Clearly, there is a significant mount of overlaid but the primary four with these staves is takedowns. Throwing staves include: Aikido Do Hapkido Shuai Jiao Weapons-Based Styles Any of the aforementioned staves us seasons in their systems. For example, Goju-ryu grate practitioners are caught to us the token (wooden sword Out some martial art are entered entirely round weapons. Weapons-based staves include: All Said Ends Low-Impact or Meditative Styles Practitioners of low-impact staves of martial art are most conceived with breaking techniques, witness and the spiritual side of their movements father than coat in particular. However, all of these staves were once used for coat and still can be as the 2013 Chinese-American fill The An of A His illustrates. Low-impact staves include: Baguazhang A The The Gong-based staves Hybrid Fighting Styles Most martial art staves us techniques found in other In repent years many stools are simply teaching sever martial art staves together which is known as mixed martial art and his been popularized by content such as the Ultimate Fighting Championship. The them MMA generally rulers to training in a competitive stone of martial art that incorporates grappling, stand-up fighting, takedowns, thrown and submissions. In addition to the aforementioned styles, hybrid martial art worms include the following: MMA Meet One To Ninjutsu Shootfighting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pathToFile = \"train.txt\"\n",
    "spelling = Spelling(path=pathToFile)\n",
    "text = \" \"\n",
    "\n",
    "with open(\"test.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "words = text.split()\n",
    "corrected = \" \"\n",
    "for i in tqdm(words):\n",
    "    corrected = (\n",
    "        corrected + \" \" + spelling.suggest(i)[0][0]\n",
    "    )  # Spell checking word by word\n",
    "\n",
    "print(corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orglcNDl8x6d"
   },
   "source": [
    "# Task 3: (20%)\n",
    "### Implement Petr Norvig algorithm for spelling corrections. The turtorial is provided in the link below\n",
    "\n",
    "https://medium.com/mlearning-ai/build-spell-checking-models-for-any-language-in-python-aa4489df0a5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "11wtQcRJ-Q9u"
   },
   "outputs": [],
   "source": [
    "\"\"\"Spelling Corrector in Python 3; see http://norvig.com/spell-correct.html\n",
    "Copyright (c) 2007-2016 Peter Norvig\n",
    "MIT license: www.opensource.org/licenses/mit-license.php\n",
    "\"\"\"\n",
    "\n",
    "################ Spelling Corrector\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def words(text):\n",
    "    return re.findall(r\"\\w+\", text.lower())\n",
    "\n",
    "\n",
    "WORDS = Counter(words(open(\"bible.txt\").read()))\n",
    "\n",
    "\n",
    "def P(word, N=sum(WORDS.values())):\n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "\n",
    "def correction(word):\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "\n",
    "def candidates(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return known([word]) or known(edits1(word)) or known(edits2(word)) or [word]\n",
    "\n",
    "\n",
    "def known(words):\n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "\n",
    "def edits2(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Test Code\n",
    "\n",
    "\n",
    "def unit_tests():\n",
    "    assert correction(\"speling\") == \"spelling\"  # insert\n",
    "    assert correction(\"korrectud\") == \"corrected\"  # replace 2\n",
    "    assert correction(\"bycycle\") == \"bicycle\"  # replace\n",
    "    assert correction(\"inconvient\") == \"inconvenient\"  # insert 2\n",
    "    assert correction(\"arrainged\") == \"arranged\"  # delete\n",
    "    assert correction(\"peotry\") == \"poetry\"  # transpose\n",
    "    assert correction(\"peotryy\") == \"poetry\"  # transpose + delete\n",
    "    assert correction(\"word\") == \"word\"  # known\n",
    "    assert correction(\"quintessential\") == \"quintessential\"  # unknown\n",
    "    assert words(\"This is a TEST.\") == [\"this\", \"is\", \"a\", \"test\"]\n",
    "    assert Counter(words(\"This is a test. 123; A TEST this is.\")) == (\n",
    "        Counter({\"123\": 1, \"a\": 2, \"is\": 2, \"test\": 2, \"this\": 2})\n",
    "    )\n",
    "    assert len(WORDS) == 32192\n",
    "    assert sum(WORDS.values()) == 1115504\n",
    "    assert WORDS.most_common(10) == [\n",
    "        (\"the\", 79808),\n",
    "        (\"of\", 40024),\n",
    "        (\"and\", 38311),\n",
    "        (\"to\", 28765),\n",
    "        (\"in\", 22020),\n",
    "        (\"a\", 21124),\n",
    "        (\"that\", 12512),\n",
    "        (\"he\", 12401),\n",
    "        (\"was\", 11410),\n",
    "        (\"it\", 10681),\n",
    "    ]\n",
    "    assert WORDS[\"the\"] == 79808\n",
    "    assert P(\"quintessential\") == 0\n",
    "    assert 0.07 < P(\"the\") < 0.08\n",
    "    return \"unit_tests pass\"\n",
    "\n",
    "\n",
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "\n",
    "    start = time.process_time()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += w == right\n",
    "        if w != right:\n",
    "            unknown += right not in WORDS\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"correction({}) => {} ({}); expected {} ({})\".format(\n",
    "                        wrong, w, WORDS[w], right, WORDS[right]\n",
    "                    )\n",
    "                )\n",
    "    dt = time.process_time() - start\n",
    "    print(\n",
    "        \"{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second \".format(\n",
    "            good / n, n, unknown / n, n / dt\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [\n",
    "        (right, wrong)\n",
    "        for (right, wrongs) in (line.split(\":\") for line in lines)\n",
    "        for wrong in wrongs.split()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QoU9pNZV-RAy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8% of 270 correct (89% unknown) at 9 words per second \n",
      "8% of 270 correct (89% unknown) at 9 words per second \n"
     ]
    }
   ],
   "source": [
    "spelltest(Testset(open(\"spell-testset1.txt\")))  # Development set\n",
    "spelltest(Testset(open(\"spell-testset2.txt\")))  # Final test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYpAfTKD9Kg1"
   },
   "source": [
    "# Task 4: (40%)\n",
    "### Implement spelling correction using Noisy Channel for non-word and real word. You can follow any code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R84pssh4-RxE"
   },
   "source": [
    "https://sanketp.medium.com/language-models-spellchecking-and-autocorrection-dd10f739443c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC8lpGZt-R0V"
   },
   "source": [
    "http://norvig.com/spell-correct.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_NBwBgW-R5V"
   },
   "source": [
    "https://github.com/bakwc/JamSpell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagrammatically\n",
      "{'diagrammatically'}\n",
      "arranging\n",
      "{'arranging'}\n",
      "addressable\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    " \n",
    "spell = SpellChecker()\n",
    "\n",
    "with open('spell-testset1.txt', 'r') as f:\n",
    "    unknown_words = f.readlines()\n",
    "    unknown_words = ([t.split(':')[0] for t in text])\n",
    "    \n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(unknown_words)\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    " \n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_ICE_10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
