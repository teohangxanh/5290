{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ELMaKQGPL1N",
    "outputId": "c3a5267b-07a8-4470-fc9e-cf1fa5ed3471"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# !pip install torch>=1.3.1\n",
    "# !pip install torchtext==0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tidDzfNnOpV9",
    "outputId": "35a4fb69-846e-4cdf-c451-bfd0e4b8d75f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import text_classification\n",
    "\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IvZbEMEEO4US"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p1kNUFr_ZuHz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_7o6i3goZitO"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6540/2054715752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmax_seq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mTEXT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"spacy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_lengths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfix_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mLABEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sequential, use_vocab, init_token, eos_token, fix_length, dtype, preprocessing, postprocessing, lower, tokenize, tokenizer_language, include_lengths, batch_first, pad_token, unk_token, pad_first, truncate_first, stop_words, is_target)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# in case the tokenizer isn't picklable (e.g. spacy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer_language\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer_language\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minclude_lengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minclude_lengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchtext\\data\\utils.py\u001b[0m in \u001b[0;36mget_tokenizer\u001b[1;34m(tokenizer, language)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mspacy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_spacy_tokenize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "max_seq_len = 50\n",
    "TEXT = data.Field(tokenize=\"spacy\", batch_first=True, include_lengths=True, fix_length=max_seq_len)\n",
    "LABEL = data.LabelField(dtype=torch.float, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urjXjeBTZe5d"
   },
   "outputs": [],
   "source": [
    "fields = [('label', LABEL), (None, None), ('text',TEXT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbU3yoPnaJPb",
    "outputId": "3204648e-dae0-469b-b0f7-5ea990f44e48"
   },
   "outputs": [],
   "source": [
    "%ls drive/MyDrive/UNT/AG_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JPQukhmZhR5"
   },
   "outputs": [],
   "source": [
    "training_data=data.TabularDataset(path = 'train.csv',format = 'csv',fields = fields,skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yS0sg4RRbdNB",
    "outputId": "083de66f-cd02-4677-f8e5-17e067f4148a"
   },
   "outputs": [],
   "source": [
    "print(vars(training_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uP8ND6Pbeoc"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = training_data.split(split_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNgRJDduZpE6",
    "outputId": "df00dac0-c8cc-4f57-dd55-cc4310b86795"
   },
   "outputs": [],
   "source": [
    "#initialize glove embeddings\n",
    "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.300d\")  \n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n",
    "\n",
    "#Word dictionary\n",
    "# print(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a5Sylp9bQG4"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits((train_data, valid_data), batch_size=batch_size,\n",
    "                                                           sort_key=lambda x: len(x.text),\n",
    "                                                           sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oeIdcP6bj7R"
   },
   "outputs": [],
   "source": [
    "# Create neural network representation\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CNNTextClassification(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_size, max_seq_len, out_channels,\n",
    "                 kernel_heights, dropout, num_class):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_heights = kernel_heights\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=self.embedding_size, out_channels=self.out_channels,\n",
    "                               kernel_size=self.kernel_heights[0]),\n",
    "                                   nn.ReLU(),\n",
    "                                  nn.MaxPool1d(self.max_seq_len - self.kernel_heights[0]+1))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=self.embedding_size, out_channels=self.out_channels,\n",
    "                               kernel_size=self.kernel_heights[1]),\n",
    "                                   nn.ReLU(),\n",
    "                                  nn.MaxPool1d(self.max_seq_len - self.kernel_heights[1]+1))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=self.embedding_size, out_channels=self.out_channels,\n",
    "                               kernel_size=self.kernel_heights[2]),\n",
    "                                   nn.ReLU(),\n",
    "                                  nn.MaxPool1d(self.max_seq_len - self.kernel_heights[2]+1))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(len(self.kernel_heights) * out_channels, num_class)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        emb = self.embedding(text).permute(0, 2, 1)\n",
    "        \n",
    "        conv_out1 = self.conv1(emb).squeeze(2)\n",
    "        conv_out2 = self.conv2(emb).squeeze(2)\n",
    "        conv_out3 = self.conv3(emb).squeeze(2)\n",
    "        \n",
    "        all_out = torch.cat((conv_out1, conv_out2, conv_out3), 1)\n",
    "        final_feature_map = self.dropout(all_out)\n",
    "        \n",
    "        final_out = self.fc(final_feature_map)\n",
    "        \n",
    "        return self.softmax(final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i41Cr_rBbpTA"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = len(TEXT.vocab)\n",
    "n_class = len(LABEL.vocab)\n",
    "embedding_size = 300\n",
    "out_channels = 100\n",
    "kernel_heights = [3, 4, 5]\n",
    "dropout = 0.4\n",
    "\n",
    "model = CNNTextClassification(vocabulary_size, embedding_size, max_seq_len,\n",
    "                              out_channels, kernel_heights, dropout, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcv1ug_ObsKX",
    "outputId": "33aa7ddb-fb32-4541-c348-ac3bc9945bd2"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LjXjhk_bvJq",
    "outputId": "5b1c2ebb-aead-48d9-ba4d-3e54eef3cdfa"
   },
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "933B6Lahbxn7"
   },
   "outputs": [],
   "source": [
    "def training(model, iterator, optimizer, criterion):\n",
    "    training_loss = 0\n",
    "    training_accuracy = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        target = batch.label\n",
    "        target = torch.autograd.Variable(target).long()\n",
    "        \n",
    "        output = model(text, text_lengths).squeeze()\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        num_corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).float().sum()\n",
    "\n",
    "        acc = num_corrects/len(batch)\n",
    "        training_accuracy += acc.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    return training_loss / len(iterator), training_accuracy / len(iterator)\n",
    "\n",
    "def testing(model, iterator, optimizer, criterion):\n",
    "    testing_loss = 0\n",
    "    testing_accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        target = batch.label\n",
    "        target = torch.autograd.Variable(target).long()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(text, text_lengths).squeeze()\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            testing_loss += loss.item()\n",
    "            num_corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).float().sum()\n",
    "            acc = num_corrects/len(batch)\n",
    "        \n",
    "            testing_accuracy += acc.item()\n",
    "            \n",
    "    return testing_loss / len(iterator), testing_accuracy / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Odj9FLsb1ac",
    "outputId": "1945bef9-2794-4214-ee0e-ed372608ef75"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 15\n",
    "min_val_loss = float(\"inf\")\n",
    "path='drive/MyDrive/UNT/AG_news/model/saved_weights_cnn.pt'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = training(model, train_iterator, optimizer, criterion)\n",
    "    val_loss, val_acc = testing(model, valid_iterator, optimizer, criterion)\n",
    "    \n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
    "    print(f'\\tLoss: {val_loss:.4f}(valid)\\t|\\tAcc: {val_acc * 100:.2f}%(valid)')\n",
    "    \n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ny6BNbBocB4Q"
   },
   "outputs": [],
   "source": [
    "testing_data=data.TabularDataset(path = 'drive/MyDrive/UNT/AG_news/test.csv',format = 'csv',fields = fields,skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G96eSYFTr5qq"
   },
   "outputs": [],
   "source": [
    "testing_iterator = data.BucketIterator(testing_data, batch_size=batch_size,\n",
    "                                                           sort_key=lambda x: len(x.text),\n",
    "                                                           sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhtYgBLFr8WT"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "def predict(model, iterator):\n",
    "    testing_accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        # text = TEXT.preprocess(text)\n",
    "        label = batch.label\n",
    "        target = torch.autograd.Variable(label).long()\n",
    "        with torch.no_grad():\n",
    "            output = model(text, text_lengths).squeeze()\n",
    "            num_corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).float().sum()\n",
    "            acc = num_corrects / len(batch)\n",
    "            testing_accuracy += acc.item()\n",
    "    \n",
    "    return testing_accuracy / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CoW5dkYr-ve",
    "outputId": "bc932e19-eb87-494c-8fc4-02d69401f378"
   },
   "outputs": [],
   "source": [
    "test_acc = predict(model, testing_iterator)\n",
    "print(f\"Accuracy {test_acc * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6nR9FjysBE1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Solution: Text_Classification_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
