{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a6afd0-3dcf-4b84-9017-d4cf981b1fc9",
   "metadata": {},
   "source": [
    "#### Import data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dccb229c-634f-4824-8484-224fd54dee73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = dt.fread('tripadvisor_hotel_reviews.csv').to_pandas()\n",
    "df.columns= df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04237696-fd96-4014-831b-e9c657493566",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b39b9b-e3c6-4590-bd4e-0374453f4022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac99f545-aa73-4c1b-a1a2-c9e8008855c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\bnt\\b', 'not', text)\n",
    "    text = re.sub(r'\\\\s{2,}', r'\\.', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Use vectorization\n",
    "df['review'] = np.vectorize(clean_text)(df['review'])\n",
    "\n",
    "# Add a column length of review \n",
    "df['review_length'] = df['review'].map(len)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f12cb59-2a90-4259-8bbc-1a8989de6bdc",
   "metadata": {},
   "source": [
    "import plotly.express as px\n",
    "import cufflinks as cf\n",
    "# This is to use iplot functions based on pandas\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "fig1 = df['review_length'].iplot(kind='hist', color='aqua', xTitle='Review length', yTitle='Frequency', title='Review length and Frequency')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3cdf77f3-7ea4-4448-a0e4-386ed2951fe5",
   "metadata": {},
   "source": [
    "fig2 = px.box(df, y=\"review_length\", color=\"rating\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79550d33-73a3-4c18-bc65-4d40e01a5a10",
   "metadata": {},
   "source": [
    "# Create a table of review length associated with different ratings\n",
    "df.groupby(by=['rating']).describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f87a303-eb8e-472c-a4e6-2ed85b916926",
   "metadata": {},
   "source": [
    "We can see the pattern that those who are more satisfied are more likely to give reviews. Also, the data set is not balanced among ratings."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b968cf7c-86cd-461f-b3ff-16479fc40a39",
   "metadata": {},
   "source": [
    "#### Play with Word Cloud"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7cc6d2b-399f-45e1-88db-c2bcf90f7d7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "def remove_sw(text):\n",
    "    # This removes stop words\n",
    "    en = spacy.load('en_core_web_sm')\n",
    "    stopwords = en.Defaults.stop_words\n",
    "    filtered_words = [t for t in text.split() if t.lower() not in stopwords]\n",
    "    return filtered_words\n",
    "\n",
    "filtered_words = remove_sw(' '.join(df['review'].tolist()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18b10585-c249-4b28-96b1-f340db71d4dc",
   "metadata": {},
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Generate a word cloud image of document\n",
    "wordcloud = WordCloud(width=780, height=450, max_font_size=50,\n",
    " background_color=\"#ffde59\").generate(' '.join(filtered_words))\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "613a86d5-798a-4267-b6dc-bc1af3b60bf2",
   "metadata": {},
   "source": [
    "* Even though this word cloud can give us a general idea how to extract features, they only handle single words instead of noun chunks.\n",
    "* I tried noun chunks but the most common phrases only existed once. It failed\n",
    "* I tried gensim summarize but it was removed\n",
    "* Is there a better way? https://explosion.ai/demos/matcher\n",
    "* https://www.youtube.com/watch?v=GQ6OT2HyfPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b36625-c508-4600-99e7-8491dee81fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(limit, total):\n",
    "    '''Splits a big chunk into equally smaller ones'''\n",
    "    total = 20491\n",
    "    limit = 1000\n",
    "    current = 0\n",
    "    chunks = []\n",
    "    while current < total:\n",
    "        chunks.append((current, current + limit))\n",
    "        current += limit\n",
    "    chunks.append((current, total))\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_features(text, pattern_list):\n",
    "    '''Uses Spacy rule-based matcher to extract phrases from a text'''\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    matcher.add('features', pattern_list, greedy='LONGEST')\n",
    "    matches = matcher(doc)\n",
    "    features = ''\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start: end]\n",
    "        features += (span.text) + '\\n'\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694a1c3f-b6d9-4069-8021-73bae0179565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned reviews to csv file \n",
    "cleaned_review_name = 'cleaned reviews.txt'\n",
    "df['review'].to_csv(cleaned_review_name, index=False, header=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3dda7c8f-8436-43cd-8362-85431660651e",
   "metadata": {},
   "source": [
    "with open(cleaned_review_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = sum(1 for _ in f)\n",
    "    chunks = get_chunks(lines // 20, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d556bf-1ca0-4244-8db5-29a41ded15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'POS': 'NOUN'}]\n",
    "with open(cleaned_review_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    for l in f:\n",
    "        nouns.add(get_features(l, [pattern]))\n",
    "        with open('extracted nouns.txt', \"a\", encoding=\"utf-8\") as extracted:\n",
    "            extracted.write(get_features(l, [pattern]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
