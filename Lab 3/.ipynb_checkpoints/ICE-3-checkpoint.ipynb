{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8hFNQohPORn"
   },
   "source": [
    "# **ICE-3: Text Preprocessing Beyond Tokenization**\n",
    "\n",
    "This notebook focuses on preprocessing English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "peiyYN47rMy1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9888/112625515.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# for using SpaCy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# for HuggingFace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# for using NLTK\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# for using SpaCy \n",
    "import spacy\n",
    "\n",
    "# for HuggingFace\n",
    "# !pip install transformers\n",
    "# !pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3Bh5T8sJXFQ"
   },
   "outputs": [],
   "source": [
    "# trick to wrap text to the viewing window for this notebook\n",
    "# Ref: https://stackoverflow.com/questions/58890109/line-wrapping-in-collaboratory-google-results\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxtJzrzGXchm"
   },
   "source": [
    "## **(Tutorial) Tokenizing text using Spacy**\n",
    "\n",
    "Following is a dummy sample of text to demonstrate tokenization in SpaCy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KP9CaD6ufac0"
   },
   "outputs": [],
   "source": [
    "dummy_text1 = \"\"\"Here is the First Paragraph and this is the First Sentence. Here is the Second Sentence. Now is the Third Sentence. This is the Fourth Sentence of the first paragaraph. This paragraph is ending now with a Fifth Sentence.\n",
    "Now, it is the Second Paragraph and its First Sentence. Here is the Second Sentence. Now is the Third Sentence. This is the Fourth Sentence of the second paragraph. This paragraph is ending now with a Fifth Sentence.\n",
    "Finally, this is the Third Paragraph and is the First Sentence of this paragraph. Here is the Second Sentence. Now is the Third Sentence. This is the Fourth Sentence of the third paragaraph. This paragraph is ending now with a Fifth Sentence.\n",
    "4th paragraph just has one sentence in it.\n",
    "\"\"\"\n",
    "\n",
    "print(dummy_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6SZCwFAfxfI"
   },
   "outputs": [],
   "source": [
    "# loads a trained English pipeline with specific preprocessing components\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# using SpaCy's tokenizer...\n",
    "doc = nlp(dummy_text1)      # applies the processing pipeline on the text\n",
    "for token in doc:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWJsFBrePj_o"
   },
   "source": [
    "### **Task 1. Revisiting Tokenization**\n",
    "\n",
    "Whitespace-based tokenization is a naive approach to tokenize text, where the idea is to extract words that are separated by whitespace characters on either sides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ci59Ry_hQq_C"
   },
   "source": [
    "#### **Question 1a. Implement the naive approach of tokenizing words (whitespace-based) for the text given in the code block below.**\n",
    "\n",
    "**Important Note:** \n",
    "1. DO NOT use any of the existing implementations for tokenization distributed as part of open-source NLP libraries.\n",
    "2. **If your solution uses readily available implementations of tokenizers, you will receive zero credit for this question.**\n",
    "3. Avoid putting additional effort to make an advanced implementation of the custom tokenizer. All your implementation needs to do is split words based on whitespace characters and that's all is expected for this question.\n",
    "4. You can ignore punctuation while building your tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQI_o_IEfR5j"
   },
   "outputs": [],
   "source": [
    "inau_text=\"\"\"The custom of delivering an address on Inauguration Day started with the very first Inauguration—George Washington’s—on April 30, 1789. After taking his oath of office on the balcony of Federal Hall in New York City, Washington proceeded to the Senate chamber where he read a speech before members of Congress and other dignitaries. His second Inauguration took place in Philadelphia on March 4, 1793, in the Senate chamber of Congress Hall. There, Washington gave the shortest Inaugural address on record—just 135 words —before repeating the oath of office.\n",
    "Every President since Washington has delivered an Inaugural address. While many of the early Presidents read their addresses before taking the oath, current custom dictates that the Chief Justice of the Supreme Court administer the oath first, followed by the President’s speech.\n",
    "William Henry Harrison delivered the longest Inaugural address, at 8,445 words, on March 4, 1841—a bitterly cold, wet day. He died one month later of pneumonia, believed to have been brought on by prolonged exposure to the elements on his Inauguration Day. John Adams’ Inaugural address, which totaled 2,308 words, contained the longest sentence, at 737 words. After Washington’s second Inaugural address, the next shortest was Franklin D. Roosevelt’s fourth address on January 20, 1945, at just 559 words. Roosevelt had chosen to have a simple Inauguration at the White House in light of the nation’s involvement in World War II.\n",
    "In 1921, Warren G. Harding became the first President to take his oath and deliver his Inaugural address through loud speakers. In 1925, Calvin Coolidge’s Inaugural address was the first to be broadcast nationally by radio. And in 1949, Harry S. Truman became the first President to deliver his Inaugural address over television airwaves.\n",
    "Most Presidents use their Inaugural address to present their vision of America and to set forth their goals for the nation. Some of the most eloquent and powerful speeches are still quoted today. In 1865, in the waning days of the Civil War, Abraham Lincoln stated, “With malice toward none, with charity for all, with firmness in the right as God gives us to see the right, let us strive on to finish the work we are in, to bind up the nation’s wounds, to care for him who shall have borne the battle and for his widow and his orphan, to do all which may achieve and cherish a just and lasting peace among ourselves and with all nations.” In 1933, Franklin D. Roosevelt avowed, “we have nothing to fear but fear itself.” And in 1961, John F. Kennedy declared, “And so my fellow Americans: ask not what your country can do for you—ask what you can do for your country.”\n",
    "Today, Presidents deliver their Inaugural address on the West Front of the Capitol, but this has not always been the case. Until Andrew Jackson’s first Inauguration in 1829, most Presidents spoke in either the House or Senate chambers. Jackson became the first President to take his oath of office and deliver his address on the East Front Portico of the U.S. Capitol in 1829. With few exceptions, the next 37 Inaugurations took place there, until 1981, when Ronald Reagan’s Swearing-In Ceremony and Inaugural address occurred on the West Front Terrace of the Capitol. The West Front has been used ever since.\"\"\"\n",
    "\n",
    "# add your code below this comment and execute it once you have written the code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jC3EqwmTSswZ"
   },
   "source": [
    "#### **Question 1b. For the same text in Q1., apply the tokenizers listed below. Analyze how the words are being tokenized by each of the tokenizers. Compare and contrast the outputs of the two tokenization schemes.**\n",
    "1. **NLTK's tokenizer**\n",
    "2. **SpaCy's tokenizer**\n",
    "\n",
    "**Note:** You are already familiar with using NLTK's tokenization which was demosntrated in the previous labs. If you do not remember, just revisit them to refresh your memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8nGNxYKQqeJ"
   },
   "outputs": [],
   "source": [
    "inau_text=\"\"\"The custom of delivering an address on Inauguration Day started with the very first Inauguration—George Washington’s—on April 30, 1789. After taking his oath of office on the balcony of Federal Hall in New York City, Washington proceeded to the Senate chamber where he read a speech before members of Congress and other dignitaries. His second Inauguration took place in Philadelphia on March 4, 1793, in the Senate chamber of Congress Hall. There, Washington gave the shortest Inaugural address on record—just 135 words —before repeating the oath of office.\n",
    "Every President since Washington has delivered an Inaugural address. While many of the early Presidents read their addresses before taking the oath, current custom dictates that the Chief Justice of the Supreme Court administer the oath first, followed by the President’s speech.\n",
    "William Henry Harrison delivered the longest Inaugural address, at 8,445 words, on March 4, 1841—a bitterly cold, wet day. He died one month later of pneumonia, believed to have been brought on by prolonged exposure to the elements on his Inauguration Day. John Adams’ Inaugural address, which totaled 2,308 words, contained the longest sentence, at 737 words. After Washington’s second Inaugural address, the next shortest was Franklin D. Roosevelt’s fourth address on January 20, 1945, at just 559 words. Roosevelt had chosen to have a simple Inauguration at the White House in light of the nation’s involvement in World War II.\n",
    "In 1921, Warren G. Harding became the first President to take his oath and deliver his Inaugural address through loud speakers. In 1925, Calvin Coolidge’s Inaugural address was the first to be broadcast nationally by radio. And in 1949, Harry S. Truman became the first President to deliver his Inaugural address over television airwaves.\n",
    "Most Presidents use their Inaugural address to present their vision of America and to set forth their goals for the nation. Some of the most eloquent and powerful speeches are still quoted today. In 1865, in the waning days of the Civil War, Abraham Lincoln stated, “With malice toward none, with charity for all, with firmness in the right as God gives us to see the right, let us strive on to finish the work we are in, to bind up the nation’s wounds, to care for him who shall have borne the battle and for his widow and his orphan, to do all which may achieve and cherish a just and lasting peace among ourselves and with all nations.” In 1933, Franklin D. Roosevelt avowed, “we have nothing to fear but fear itself.” And in 1961, John F. Kennedy declared, “And so my fellow Americans: ask not what your country can do for you—ask what you can do for your country.”\n",
    "Today, Presidents deliver their Inaugural address on the West Front of the Capitol, but this has not always been the case. Until Andrew Jackson’s first Inauguration in 1829, most Presidents spoke in either the House or Senate chambers. Jackson became the first President to take his oath of office and deliver his address on the East Front Portico of the U.S. Capitol in 1829. With few exceptions, the next 37 Inaugurations took place there, until 1981, when Ronald Reagan’s Swearing-In Ceremony and Inaugural address occurred on the West Front Terrace of the Capitol. The West Front has been used ever since.\"\"\"\n",
    "\n",
    "# add your code below this comment and execute it once you have written the code.\n",
    "# you can additional code cells if need be. make sure to use the text cell provided to answer the question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SLPwJPOXKf9"
   },
   "source": [
    "**Answer for Q1b.** Type in your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgaX-Ck7YYzY"
   },
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNUmlAHIQ9gs"
   },
   "source": [
    "## **(Tutorial) Stemming and Lemmatization using NLTK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jCebsYwiQxf"
   },
   "source": [
    "Let's see how we can perform stemming and lemmatization using NLTK library..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3M0mDUIiSdu"
   },
   "outputs": [],
   "source": [
    "# importing PorterStemmer class from nltk.stem module\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()    # instantiating an object of the PorterStemmer class\n",
    "\n",
    "stem = porter.stem('cats')    # calling the stemmer algorithm on the desired word\n",
    "print(f\"'cats' after stemming: {stem}\")\n",
    "\n",
    "stem = porter.stem('better')\n",
    "print(f\"'better' after stemming: {stem}\")\n",
    "\n",
    "stem = porter.stem('abaci')\n",
    "print(f\"'abaci' after stemming: {stem}\")\n",
    "\n",
    "stem = porter.stem('aardwolves')\n",
    "print(f\"'aardwolves' after stemming: {stem}\")\n",
    "\n",
    "stem = porter.stem('generically')\n",
    "print(f\"'generically' after stemming: {stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Jo-qgQfjuli"
   },
   "outputs": [],
   "source": [
    "# importing WordNet-based lemmatizer class from nltk.stem module\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()    # instantiating an object of the WordNetLemmatizer class\n",
    "\n",
    "lemma = lemmatizer.lemmatize('cats')    # calling the lemmatization algorithm on the desired word\n",
    "print(f\"'cats' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('better')\n",
    "print(f\"'better' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('abaci')\n",
    "print(f\"'abaci' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('aardwolves')\n",
    "print(f\"'aardwolves' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('generically')\n",
    "print(f\"'generically' after lemmatization: {lemma}\")\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "lemma = lemmatizer.lemmatize('better', pos='a')   # 'a' denoted ADJECTIVE part-of-speech\n",
    "print(f\"'better' (as an adjective) after lemmatization: {lemma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDGVeoHqrQkF"
   },
   "source": [
    "### **Task 2: Lemmatization or Stemming?**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3K_-XgVmKin"
   },
   "source": [
    "Following is the text that you will be using for this task (Task 2 only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCtK0QouYj2d"
   },
   "outputs": [],
   "source": [
    "# This is the text on which you have to perform stemming; taken from Wikipedia.\n",
    "text = \"In linguistic morphology and information retrieval, stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form; generally a written word form. The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root.\"\n",
    "print(\"Given text:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxubbVwPmSsO"
   },
   "source": [
    "Performing some preprocessing that we have learnt in previous ICEs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "el7w7c7HmY9a"
   },
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words('english'))\n",
    "def remove_punc(text_string):\n",
    "  return re.sub('[^a-zA-Z0-9 ]', '', text_string.lower())\n",
    "\n",
    "def remove_stopwords(text_string):\n",
    "  return [ token for token in text_string.split(' ') if token not in en_stopwords ]\n",
    "\n",
    "# applying punctuation removal to the text\n",
    "unpunc_text = remove_punc(text)\n",
    "print(\"After punctuation removal:\")\n",
    "print(unpunc_text)\n",
    "\n",
    "# # applying stopword removal to the text\n",
    "clean_text = remove_stopwords(unpunc_text)\n",
    "print(\"\\n\\nAfter stopword removal:\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac5uju7eGVfg"
   },
   "source": [
    "#### **Question 2. Perform stemming on the cleaned text above using the Porter Stemmer from NLTK.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAC8FFLCErdI"
   },
   "outputs": [],
   "source": [
    "# apply Porter Stemmer on the cleaned text (after punctuation and stopwords are removed) below this comment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N44TNDasS6eK"
   },
   "source": [
    "#### **Question 3. Perform lemmatization on the same cleaned text above using NLTK's lemmatizer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJ-moA25Erh3"
   },
   "outputs": [],
   "source": [
    "# apply NLTK's lemmatizer on the cleaned text (after punctuation and stopwords are removed) below this comment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v93jILmOT9mG"
   },
   "source": [
    "#### **Question 4. What do you think is better - Lemmatization or Stemming?**\n",
    "\n",
    "**IMPORTANT NOTE: Substantiate your answer not just based on your observations from solving Questions 2. and 3. but also from your understanding about language in general. Additionally, think about if there are cases where one performs better than the other.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS-ZjxoOURAJ"
   },
   "source": [
    "**Answer for Q4.:** Type your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJNe9XfmOcqi"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lixVq2oOP1VP"
   },
   "source": [
    "## **(Tutorial) Sentence Segmentation using Spacy**\n",
    "\n",
    "Following is a dummy paragraph of text to demonstrate how to use SpaCy to segment text into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuFV_nccQq6u"
   },
   "outputs": [],
   "source": [
    "dummy_text3 = \"\"\"Here is the First Paragraph and this is the First Sentence. Here is the Second Sentence. Now is the Third Sentence. This is the Fourth Sentence of the first paragaraph. This paragraph is ending now with a Fifth Sentence.\n",
    "Now, it is the Second Paragraph and its First Sentence. Here is the Second Sentence. Now is the Third Sentence. This is the Fourth Sentence of the second paragraph. This paragraph is ending now with a Fifth Sentence.\n",
    "Finally, this is the Third Paragraph and is the First Sentence of this paragraph. Here is the Second Sentence. Now is the Third Sentence. This is the Fourth Sentence of the third paragaraph. This paragraph is ending now with a Fifth Sentence.\n",
    "4th paragraph just has one sentence in it.\n",
    "\"\"\"\n",
    "\n",
    "print(dummy_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtuBXdrAQC94"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# performing sentence splitting...\n",
    "doc = nlp(dummy_text3)\n",
    "for sentence in doc.sents:\n",
    "  print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtQeRGq9Q_mz"
   },
   "source": [
    "\n",
    "### **Task 3. Segmenting Sentences**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW9TyShiSnt2"
   },
   "source": [
    "For this task, we will be using the [*Inaugural Address*](https://www.inaugural.senate.gov/inaugural-address/) text excerpt that we used in ICE-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jg4DnVjvSoTi"
   },
   "outputs": [],
   "source": [
    "inau_text=\"\"\"The custom of delivering an address on Inauguration Day started with the very first Inauguration—George Washington’s—on April 30, 1789. After taking his oath of office on the balcony of Federal Hall in New York City, Washington proceeded to the Senate chamber where he read a speech before members of Congress and other dignitaries. His second Inauguration took place in Philadelphia on March 4, 1793, in the Senate chamber of Congress Hall. There, Washington gave the shortest Inaugural address on record—just 135 words —before repeating the oath of office.\n",
    "Every President since Washington has delivered an Inaugural address. While many of the early Presidents read their addresses before taking the oath, current custom dictates that the Chief Justice of the Supreme Court administer the oath first, followed by the President’s speech.\n",
    "William Henry Harrison delivered the longest Inaugural address, at 8,445 words, on March 4, 1841—a bitterly cold, wet day. He died one month later of pneumonia, believed to have been brought on by prolonged exposure to the elements on his Inauguration Day. John Adams’ Inaugural address, which totaled 2,308 words, contained the longest sentence, at 737 words. After Washington’s second Inaugural address, the next shortest was Franklin D. Roosevelt’s fourth address on January 20, 1945, at just 559 words. Roosevelt had chosen to have a simple Inauguration at the White House in light of the nation’s involvement in World War II.\n",
    "In 1921, Warren G. Harding became the first President to take his oath and deliver his Inaugural address through loud speakers. In 1925, Calvin Coolidge’s Inaugural address was the first to be broadcast nationally by radio. And in 1949, Harry S. Truman became the first President to deliver his Inaugural address over television airwaves.\n",
    "Most Presidents use their Inaugural address to present their vision of America and to set forth their goals for the nation. Some of the most eloquent and powerful speeches are still quoted today. In 1865, in the waning days of the Civil War, Abraham Lincoln stated, “With malice toward none, with charity for all, with firmness in the right as God gives us to see the right, let us strive on to finish the work we are in, to bind up the nation’s wounds, to care for him who shall have borne the battle and for his widow and his orphan, to do all which may achieve and cherish a just and lasting peace among ourselves and with all nations.” In 1933, Franklin D. Roosevelt avowed, “we have nothing to fear but fear itself.” And in 1961, John F. Kennedy declared, “And so my fellow Americans: ask not what your country can do for you—ask what you can do for your country.”\n",
    "Today, Presidents deliver their Inaugural address on the West Front of the Capitol, but this has not always been the case. Until Andrew Jackson’s first Inauguration in 1829, most Presidents spoke in either the House or Senate chambers. Jackson became the first President to take his oath of office and deliver his address on the East Front Portico of the U.S. Capitol in 1829. With few exceptions, the next 37 Inaugurations took place there, until 1981, when Ronald Reagan’s Swearing-In Ceremony and Inaugural address occurred on the West Front Terrace of the Capitol. The West Front has been used ever since.\"\"\"\n",
    "\n",
    "print(inau_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVHl6V3eVudZ"
   },
   "source": [
    "#### **Question 5a. Implement a custom Python script that performs a simple way of segmenting sentences in the text above by using the period (.) character as the sentence boundary. Analyze the generated output and provide your observations.**\n",
    "\n",
    "**Note:** You do not need to remove any stopwords, punctuation or apply any kind of other preprocessing techniques. Only perform what's asked to minimize your effort needed to answer this question. \n",
    "\n",
    "**Hint**: Use print( ) to help you understand how the sentences are being split when analyzing your output to note down your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZBRbBDuWogQ"
   },
   "outputs": [],
   "source": [
    "# write your code below this comment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id9ygYT6Wo6b"
   },
   "source": [
    "#### **Question 5b. Using SpaCy, perform sentence segmentation on the same text (that was used in Q5a.). Analyze the generated output and provide your observations.**\n",
    "\n",
    "**Hint**: Use print( ) to help you understand how the sentences are being split when analyzing your output to note down your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Urwzg2zNWpD7"
   },
   "outputs": [],
   "source": [
    "# write your code below this comment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiEaJ3RuSmeU"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYE8A-Mk4BKe"
   },
   "source": [
    "## **(Tutorial) Subword Tokenization using HuggingFace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bV2KUGEhIm2M"
   },
   "outputs": [],
   "source": [
    "!pip install tokenizers\n",
    "\n",
    "!wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-vocab.json\n",
    "!wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyiWXf-hLtRF"
   },
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "gpt2vocab = \"gpt2-medium-vocab.json\"\n",
    "gpt2merges = \"gpt2-merges.txt\"\n",
    "\n",
    "bpe = ByteLevelBPETokenizer(gpt2vocab, gpt2merges)\n",
    "bpe_encoding = bpe.encode(\"The custom of delivering an address on Inauguration Day started with the very first Inauguration—George Washington’s—on April 30, 1789.\")\n",
    "print(bpe_encoding.ids)\n",
    "print(bpe_encoding.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4J8U2pWSc8v"
   },
   "source": [
    "### **Task 4: Understanding Subword Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yS4dlR20V1eX"
   },
   "source": [
    "Consider the following two sentences:\n",
    "\n",
    "* I like yellow roses better than red ones.\n",
    "* Looks like John is bettering the working conditions at his organization.\n",
    "\n",
    "\n",
    "**Question 6. Encode these sentences using the Byte-Pair Encoding tokenizer (created during the tutorial). Retrieve the tokens from the encodings of the two sentences. Is/Are there any interesting observations when you compare the tokens between the two encodings? What do you think is causing what you observe as part of your comparison?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhCV2qCPNMGe"
   },
   "outputs": [],
   "source": [
    "# use the bpe tokenizer that was created during the tutorial to encode the sentences\n",
    "# write your code below this comment and execute\n",
    "# type in your answer to the question asked above in the following cell (see below)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE9RMvKXUcVx"
   },
   "source": [
    "**Answer for Q6.:** Type your answer in here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QS106hEUx1R"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-K9BsX3KcC6y"
   },
   "source": [
    "## **References**\n",
    "* https://spacy.io/usage/spacy-101\n",
    "* https://spacy.io/models/en\n",
    "* https://www.nltk.org/howto/wordnet.html\n",
    "* https://www.nltk.org/_modules/nltk/stem/wordnet.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uxtJzrzGXchm",
    "XWJsFBrePj_o",
    "aNUmlAHIQ9gs",
    "eDGVeoHqrQkF",
    "lixVq2oOP1VP",
    "YtQeRGq9Q_mz",
    "eYE8A-Mk4BKe",
    "O4J8U2pWSc8v"
   ],
   "name": "ICE-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
